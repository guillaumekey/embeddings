import streamlit as st
import pandas as pd
from typing import Dict, List


def display_theme_analysis(theme_df: pd.DataFrame, min_cluster_size: int):
    """Affiche l'analyse th√©matique."""
    themes = theme_df['Theme'].value_counts()
    valid_themes = themes[themes >= min_cluster_size].index

    total_themes = len(themes)
    valid_clusters = len(valid_themes)

    st.info(f"Sur {total_themes} th√®mes d√©tect√©s, {valid_clusters} ont au moins {min_cluster_size} pages.")

    for theme in valid_themes:
        theme_subset = theme_df[theme_df['Theme'] == theme]
        with st.expander(
                f"üìö {theme} ({len(theme_subset)} pages, dont {theme_subset['Nombre de relations inter-th√©matiques'].sum()} relations inter-th√©matiques)"):
            display_cols = [
                'URL',
                'Nombre de pages similaires',
                'Nombre de relations inter-th√©matiques',
                'Score moyen',
                'Relations inter-th√©matiques',
                'Pages similaires'
            ]

            st.dataframe(
                theme_subset[display_cols],
                column_config={
                    'URL': 'URL',
                    'Nombre de pages similaires': st.column_config.NumberColumn('Pages similaires'),
                    'Nombre de relations inter-th√©matiques': st.column_config.NumberColumn(
                        'Relations inter-th√©matiques'),
                    'Score moyen': st.column_config.NumberColumn('Score moyen', format="%.3f"),
                    'Relations inter-th√©matiques': 'D√©tails des relations inter-th√©matiques',
                    'Pages similaires': 'Pages similaires'
                },
                use_container_width=True,
                hide_index=True
            )


def display_link_analysis(link_stats: dict):
    """Affiche les statistiques de liens."""
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Pages totales", link_stats['total_pages'])
        st.metric("Pages avec liens sortants", link_stats['pages_with_links'])
    with col2:
        st.metric("Nombre total de liens", link_stats['total_links'])
        st.metric("Moyenne de liens par page", f"{link_stats['avg_links_per_page']:.2f}")
    with col3:
        st.metric("Pages orphelines", link_stats['orphan_pages'])
        st.metric("% pages orphelines", f"{(link_stats['orphan_pages'] / link_stats['total_pages'] * 100):.1f}%")


def display_link_recommendations(link_analysis_df: pd.DataFrame):
    """Affiche les recommandations de liens."""
    st.dataframe(
        link_analysis_df,
        column_config={
            "URL": "URL",
            "Nombre de liens internes re√ßus": st.column_config.NumberColumn(
                "Liens re√ßus",
                help="Nombre de liens internes pointant vers cette page"
            ),
            "Nombre de liens internes recommand√©s": st.column_config.NumberColumn(
                "Liens manquants recommand√©s",
                help="Nombre de liens potentiels bas√© sur la similarit√© s√©mantique"
            )
        },
        use_container_width=True,
        hide_index=True
    )


def display_similarity_details(related_pages: Dict[str, List[Dict]], min_score: float) -> pd.DataFrame:
    """
    Cr√©e et affiche une table d√©taill√©e des similarit√©s avec une URL par ligne,
    en √©vitant les doublons de relations.

    Args:
        related_pages: Dictionnaire des pages similaires
        min_score: Score minimum de similarit√© √† afficher

    Returns:
        DataFrame contenant les d√©tails des similarit√©s
    """
    # Cr√©ation de la liste des similarit√©s
    similarity_data = []
    processed_pairs = set()  # Pour suivre les paires d√©j√† trait√©es

    for source_url, similar_pages in related_pages.items():
        for page in similar_pages:
            if page['score'] >= min_score:
                target_url = page['url']

                # Cr√©er une paire tri√©e pour √©viter les doublons
                pair = tuple(sorted([source_url, target_url]))

                # Ne traiter la paire que si elle n'a pas d√©j√† √©t√© vue
                if pair not in processed_pairs:
                    similarity_data.append({
                        'URL principale': pair[0],
                        'URL similaire': pair[1],
                        'Score de similarit√©': page['score']
                    })
                    processed_pairs.add(pair)

    # Cr√©ation du DataFrame
    similarity_df = pd.DataFrame(similarity_data)

    if not similarity_df.empty:
        # Tri par score de similarit√© d√©croissant
        similarity_df = similarity_df.sort_values('Score de similarit√©', ascending=False)

        # Affichage du tableau
        st.dataframe(
            similarity_df,
            column_config={
                'URL principale': st.column_config.TextColumn(
                    'URL principale',
                    width='large'
                ),
                'URL similaire': st.column_config.TextColumn(
                    'URL similaire',
                    width='large'
                ),
                'Score de similarit√©': st.column_config.NumberColumn(
                    'Score de similarit√©',
                    format="%.3f"
                )
            },
            use_container_width=True,
            hide_index=True
        )
    else:
        st.info("Aucune similarit√© trouv√©e avec le score minimum s√©lectionn√©.")

    return similarity_df